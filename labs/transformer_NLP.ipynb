{"cells":[{"cell_type":"code","execution_count":null,"id":"d5d84c38","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-30T16:46:29.585063Z","iopub.status.busy":"2024-08-30T16:46:29.584369Z","iopub.status.idle":"2024-08-30T16:46:33.301087Z","shell.execute_reply":"2024-08-30T16:46:33.300147Z"},"papermill":{"duration":3.731108,"end_time":"2024-08-30T16:46:33.303503","exception":false,"start_time":"2024-08-30T16:46:29.572395","status":"completed"},"tags":[],"id":"d5d84c38"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math\n","import numpy as np\n","import numpy"]},{"cell_type":"markdown","id":"f595af1b","metadata":{"id":"f595af1b"},"source":["### Use this versions to run the following code\n","\n","torch==2.0.1\n","\n","torchvision==0.15.2\n","\n","torchaudio==2.0.2\n","\n","torchtext==0.15.2\n","\n","datasets==2.15.0\n","\n","tokenizers==0.13.3\n","\n","torchmetrics==1.0.3\n","\n","tensorboard==2.13.0\n","\n","altair==5.1.1\n","\n","wandb==0.15.9\n","\n","numpy==1.24.2"]},{"cell_type":"code","execution_count":null,"id":"37e92bc4","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.324119Z","iopub.status.busy":"2024-08-30T16:46:33.323762Z","iopub.status.idle":"2024-08-30T16:46:33.327969Z","shell.execute_reply":"2024-08-30T16:46:33.327192Z"},"papermill":{"duration":0.016625,"end_time":"2024-08-30T16:46:33.329900","exception":false,"start_time":"2024-08-30T16:46:33.313275","status":"completed"},"tags":[],"id":"37e92bc4"},"outputs":[],"source":["# class TokenEmbedding(nn.Module):\n","\n","#     def __init__(self):\n","#         super(TokenEmbedding, self).__init__()\n","#         self.d_model =512\n","#         self.vocab_size =1000\n","#         self.embedding = nn.Embedding(num_embeddings = self.vocab_size,\n","#                                      embedding_dim=self.d_model)\n","\n","#     def forward(self,x):\n","#         token_embedding = self.embedding(x)\n","\n","#         return token_embedding"]},{"cell_type":"code","execution_count":null,"id":"403710a6","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.349931Z","iopub.status.busy":"2024-08-30T16:46:33.349672Z","iopub.status.idle":"2024-08-30T16:46:33.353334Z","shell.execute_reply":"2024-08-30T16:46:33.352530Z"},"papermill":{"duration":0.015879,"end_time":"2024-08-30T16:46:33.355282","exception":false,"start_time":"2024-08-30T16:46:33.339403","status":"completed"},"tags":[],"id":"403710a6"},"outputs":[],"source":["# a = TokenEmbedding()"]},{"cell_type":"code","execution_count":null,"id":"6385f036","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.375341Z","iopub.status.busy":"2024-08-30T16:46:33.375033Z","iopub.status.idle":"2024-08-30T16:46:33.378560Z","shell.execute_reply":"2024-08-30T16:46:33.377793Z"},"papermill":{"duration":0.015813,"end_time":"2024-08-30T16:46:33.380548","exception":false,"start_time":"2024-08-30T16:46:33.364735","status":"completed"},"tags":[],"id":"6385f036"},"outputs":[],"source":["# input_tensor = torch.LongTensor([1, 2, 3, 4])  # Example input tensor\n","# output = a(input_tensor)\n","# print(output)"]},{"cell_type":"code","execution_count":null,"id":"83b2d26e","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.401204Z","iopub.status.busy":"2024-08-30T16:46:33.400425Z","iopub.status.idle":"2024-08-30T16:46:33.404934Z","shell.execute_reply":"2024-08-30T16:46:33.404087Z"},"papermill":{"duration":0.016781,"end_time":"2024-08-30T16:46:33.406862","exception":false,"start_time":"2024-08-30T16:46:33.390081","status":"completed"},"tags":[],"id":"83b2d26e"},"outputs":[],"source":["# class PositionalEncoding(nn.Module):\n","#     def __init__(self):\n","#         super(PositionalEncoding,self).__init__()\n","#         self.d_model = 512\n","#         self.seq_length = 512\n","#         self.dropout_p = 0.2\n","\n","#         self.dropout = nn.Dropout(self.dropout_p)\n","#         position_encoding = torch.zeros(self.seq_length,self.d_model)\n","#         position = torch.arange(0,self.seq_length,dtype= torch.float).unsqueeze(1)\n","#         even_odd_position = torch.arange(0,self.d_model,2).float()\n","#         div_term = torch.pow(10000,even_odd_position/self.d_model)\n","#         position_encoding[:,0::2] = torch.sin(position*div_term)\n","#         position_encoding[:,1::2] = torch.cos(position*div_term)\n","#         position_encoding = position_encoding.unsqueeze(0)\n","#         self.register_buffer('position_encoding', position_encoding)\n","\n","#     def forward(self,x):\n","#         x =x +(self.positional_encoding[:,:x.shape[1],:]).requires_grad_(False)\n","#         x =self.dropout(x)\n","#         return x"]},{"cell_type":"code","execution_count":null,"id":"5e9a1fea","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.427063Z","iopub.status.busy":"2024-08-30T16:46:33.426381Z","iopub.status.idle":"2024-08-30T16:46:33.430128Z","shell.execute_reply":"2024-08-30T16:46:33.429279Z"},"papermill":{"duration":0.015768,"end_time":"2024-08-30T16:46:33.432214","exception":false,"start_time":"2024-08-30T16:46:33.416446","status":"completed"},"tags":[],"id":"5e9a1fea"},"outputs":[],"source":["# b = PositionalEncoding()"]},{"cell_type":"code","execution_count":null,"id":"870c542f","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.452961Z","iopub.status.busy":"2024-08-30T16:46:33.452449Z","iopub.status.idle":"2024-08-30T16:46:33.456605Z","shell.execute_reply":"2024-08-30T16:46:33.455664Z"},"papermill":{"duration":0.016137,"end_time":"2024-08-30T16:46:33.458579","exception":false,"start_time":"2024-08-30T16:46:33.442442","status":"completed"},"tags":[],"id":"870c542f"},"outputs":[],"source":["# class InputEmbedding(nn.Module):\n","#     def __init__(self,positional_encoding,token_embeddings):\n","#         super(InputEmbedding,self).__init__()\n","#         self.d_model = 512\n","#         self.vocab_size = 1000\n","#         self.seq_len = 512\n","#         self.dropout_p = 0.2\n","#         self.token_embedding = token_embeddings\n","#         self.positional_encoding = positional_encoding\n","\n","#     def forward(self,x):\n","#         x = self.token_embedding(x)\n","#         x = self.positional_encoding(x)\n","\n","#         return x"]},{"cell_type":"code","execution_count":null,"id":"9fab2a33","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.479869Z","iopub.status.busy":"2024-08-30T16:46:33.479631Z","iopub.status.idle":"2024-08-30T16:46:33.483245Z","shell.execute_reply":"2024-08-30T16:46:33.482441Z"},"papermill":{"duration":0.017356,"end_time":"2024-08-30T16:46:33.485183","exception":false,"start_time":"2024-08-30T16:46:33.467827","status":"completed"},"tags":[],"id":"9fab2a33"},"outputs":[],"source":["# token_embeddings = TokenEmbedding()\n","# positional_encoding = PositionalEncoding()\n","# InputEmbedding(positional_encoding,token_embeddings)"]},{"cell_type":"markdown","source":["### Input"],"metadata":{"id":"l5cCJg1TwwMt"},"id":"l5cCJg1TwwMt"},{"cell_type":"code","execution_count":null,"id":"0731d7d4","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.504952Z","iopub.status.busy":"2024-08-30T16:46:33.504703Z","iopub.status.idle":"2024-08-30T16:46:33.515360Z","shell.execute_reply":"2024-08-30T16:46:33.514501Z"},"papermill":{"duration":0.022804,"end_time":"2024-08-30T16:46:33.517221","exception":false,"start_time":"2024-08-30T16:46:33.494417","status":"completed"},"tags":[],"id":"0731d7d4"},"outputs":[],"source":["class InputEmbeddings(nn.Module):\n","\n","    def __init__(self, d_model: int, vocab_size: int) -> None:\n","        super().__init__()\n","        self.d_model = d_model\n","        self.vocab_size = vocab_size  #seq_len hyperparameter = max(sentence_len)\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","\n","    def forward(self, x):\n","        # (batch, seq_len) --> (batch, seq_len, d_model)\n","        # Multiply by sqrt(d_model) to scale the embeddings according to the paper\n","        return self.embedding(x) * math.sqrt(self.d_model)\n","\n","class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n","        super().__init__()\n","        self.d_model = d_model\n","        self.seq_len = seq_len\n","        self.dropout = nn.Dropout(dropout)\n","        # Create a matrix of shape (seq_len, d_model)\n","        pe = torch.zeros(seq_len, d_model)\n","        # Create a vector of shape (seq_len)\n","        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n","        # Create a vector of shape (d_model)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n","        # Apply sine to even indices\n","        pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model))\n","        # Apply cosine to odd indices\n","        pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model))\n","        # Add a batch dimension to the positional encoding\n","        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n","        # Register the positional encoding as a buffer\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)\n","        return self.dropout(x)\n"]},{"cell_type":"code","execution_count":null,"id":"25533a60","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.537041Z","iopub.status.busy":"2024-08-30T16:46:33.536399Z","iopub.status.idle":"2024-08-30T16:46:33.540371Z","shell.execute_reply":"2024-08-30T16:46:33.539569Z"},"papermill":{"duration":0.015997,"end_time":"2024-08-30T16:46:33.542357","exception":false,"start_time":"2024-08-30T16:46:33.526360","status":"completed"},"tags":[],"id":"25533a60"},"outputs":[],"source":["# class LayerNormalization(nn.Module):\n","#     def __init__(self,features,eps=10**-6):\n","#         super().__init__()\n","#         self.d_model = 512\n","#         self.eps = 10**-6\n","#         self.alph = nn.Parameter(torch.ones(self.d_model))\n","#         self.beta = nn.Parameter(torch.ones(self.d_model))\n","\n","#     def forward(self,x):\n","#         mean = x.mean(dim = -1,keepdim = True)\n","#         std = x.std(dim = -1 , keepdim = True)\n","#         norm = (x-mean)/(std + self.eps)\n","#         layer_norm = self.alpha * norm + self.beta\n","#         return layer_norm"]},{"cell_type":"markdown","source":["### Layer Normalization"],"metadata":{"id":"iy4bESDuw1d0"},"id":"iy4bESDuw1d0"},{"cell_type":"code","execution_count":null,"id":"c50d7298","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.562104Z","iopub.status.busy":"2024-08-30T16:46:33.561828Z","iopub.status.idle":"2024-08-30T16:46:33.568164Z","shell.execute_reply":"2024-08-30T16:46:33.567380Z"},"papermill":{"duration":0.018528,"end_time":"2024-08-30T16:46:33.570251","exception":false,"start_time":"2024-08-30T16:46:33.551723","status":"completed"},"tags":[],"id":"c50d7298"},"outputs":[],"source":["class LayerNormalization(nn.Module):\n","\n","    def __init__(self, features: int, eps:float=10**-6) -> None:\n","        super().__init__()\n","        self.eps = eps\n","        self.alpha = nn.Parameter(torch.ones(features)) # alpha is a learnable parameter\n","        self.bias = nn.Parameter(torch.zeros(features)) # bias is a learnable parameter\n","\n","    def forward(self, x):\n","        # x: (batch, seq_len, hidden_size)\n","         # Keep the dimension for broadcasting\n","        mean = x.mean(dim = -1, keepdim = True) # (batch, seq_len, 1)\n","        # Keep the dimension for broadcasting\n","        std = x.std(dim = -1, keepdim = True) # (batch, seq_len, 1)\n","        # eps is to prevent dividing by zero or when std is very small\n","        return self.alpha * (x - mean) / (std + self.eps) + self.bias"]},{"cell_type":"markdown","source":["### Feed Forward"],"metadata":{"id":"AInJuArgw46H"},"id":"AInJuArgw46H"},{"cell_type":"code","execution_count":null,"id":"7b50db9a","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.590503Z","iopub.status.busy":"2024-08-30T16:46:33.590177Z","iopub.status.idle":"2024-08-30T16:46:33.596341Z","shell.execute_reply":"2024-08-30T16:46:33.595518Z"},"papermill":{"duration":0.01829,"end_time":"2024-08-30T16:46:33.598170","exception":false,"start_time":"2024-08-30T16:46:33.579880","status":"completed"},"tags":[],"id":"7b50db9a"},"outputs":[],"source":["class FeedForwardBlock(nn.Module):\n","    def __init__(self,d_model,d_ff):\n","        super().__init__(self)\n","        self.d_model = d_model\n","        self.d_ff = d_ff\n","\n","        self.first_layer = nn.Linear(d_model,d_ff)\n","        self.second_layer = nn.Linear(d_ff,d_model)\n","        self.dropout = nn.Dropout(0.2)\n","\n","\n","    def forward(self,x):\n","        x = self.first_layer(x)\n","        x = nn.ReLU(x)\n","        x = self.dropout(x)\n","        x = self.second_layer(x)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":null,"id":"eadcc840","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.617664Z","iopub.status.busy":"2024-08-30T16:46:33.617372Z","iopub.status.idle":"2024-08-30T16:46:33.623180Z","shell.execute_reply":"2024-08-30T16:46:33.622399Z"},"papermill":{"duration":0.017702,"end_time":"2024-08-30T16:46:33.625004","exception":false,"start_time":"2024-08-30T16:46:33.607302","status":"completed"},"tags":[],"id":"eadcc840"},"outputs":[],"source":["class FeedForwardBlock(nn.Module):\n","\n","    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n","        super().__init__()\n","        self.linear_1 = nn.Linear(d_model, d_ff) # w1 and b1\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model) # w2 and b2\n","\n","    def forward(self, x):\n","        # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)\n","        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\n"]},{"cell_type":"markdown","source":["### Multihead Attention"],"metadata":{"id":"vtCp-r2DxGIx"},"id":"vtCp-r2DxGIx"},{"cell_type":"code","execution_count":null,"id":"0fdb8f64","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.644800Z","iopub.status.busy":"2024-08-30T16:46:33.644530Z","iopub.status.idle":"2024-08-30T16:46:33.657236Z","shell.execute_reply":"2024-08-30T16:46:33.656474Z"},"papermill":{"duration":0.02473,"end_time":"2024-08-30T16:46:33.659034","exception":false,"start_time":"2024-08-30T16:46:33.634304","status":"completed"},"tags":[],"id":"0fdb8f64"},"outputs":[],"source":["class MultiHeadAttentionBlock(nn.Module):\n","    def __init__(self,d_model,head):\n","        super().__init__(self)\n","        self.d_model = d_model\n","        self.head = head\n","        self.hread_dim = d_model // head\n","        self.wq = nn.Linear(d_model,d_model , bias = True)\n","        self.wk = nn.Linear(d_model,d_model , bias = True)\n","        self.wv = nn.Linear(d_model,d_model , bias = True)\n","        self.wo = nn.Linear(d_model,d_model , bias = True)\n","        self.dropout = nn.Dropout(0.2)\n","\n","\n","    @staticmethod\n","    def attention(query, key, value, mask, dropout: nn.Dropout):\n","        d_k =query.shape[-1]\n","\n","        attention_scores = (query @ key.transpose(-2,-1))/math.squrt(d_k)\n","\n","        if mask is not None:\n","            attention_scores.masked_fill_(mask == 0,-1e9)\n","\n","        attention_scores = attention_scores.softmax(dim=-1)\n","        if dropout is not None:\n","            attention_scores = dropout(attention_scores)\n","\n","        return (attention_scores @ value), attention_scores\n","\n","\n","    def forward(self,q,k,v,mask):\n","        query = self.wq(q)\n","        key = self.wk(k)\n","        value = self.wv(v)\n","\n","\n","        query = query.view(query.shape[0],query.shape[1],self.h,self.d_k).transpose(1,2)\n","        value = value.view(value.shape[0],value.shape[1],self.h,self.d_k).transpose(1,2)\n","        key   = key.view(key.shape[0],key.shape[1],self.h,self.d_k).transpose(1,2)\n","\n","        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n","\n","        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n","\n","        return self.wo(x)\n"]},{"cell_type":"code","execution_count":null,"id":"b70714ee","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.679335Z","iopub.status.busy":"2024-08-30T16:46:33.679040Z","iopub.status.idle":"2024-08-30T16:46:33.692923Z","shell.execute_reply":"2024-08-30T16:46:33.692142Z"},"papermill":{"duration":0.026276,"end_time":"2024-08-30T16:46:33.694826","exception":false,"start_time":"2024-08-30T16:46:33.668550","status":"completed"},"tags":[],"id":"b70714ee"},"outputs":[],"source":["class MultiHeadAttentionBlock(nn.Module):\n","\n","    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n","        super().__init__()\n","        self.d_model = d_model # Embedding vector size\n","        self.h = h # Number of heads\n","        # Make sure d_model is divisible by h\n","        assert d_model % h == 0, \"d_model is not divisible by h\"\n","\n","        self.d_k = d_model // h # Dimension of vector seen by each head\n","        self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n","        self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n","        self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n","        self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n","        self.dropout = nn.Dropout(dropout)\n","\n","    @staticmethod\n","    def attention(query, key, value, mask, dropout: nn.Dropout):\n","        d_k = query.shape[-1]\n","        # Just apply the formula from the paper\n","        # (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n","        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n","        if mask is not None:\n","            # Write a very low value (indicating -inf) to the positions where mask == 0\n","            attention_scores.masked_fill_(mask == 0, -1e9)\n","        attention_scores = attention_scores.softmax(dim=-1) # (batch, h, seq_len, seq_len) # Apply softmax\n","        if dropout is not None:\n","            attention_scores = dropout(attention_scores)\n","        # (batch, h, seq_len, seq_len) --> (batch, h, seq_len, d_k)\n","        # return attention scores which can be used for visualization\n","        return (attention_scores @ value), attention_scores\n","\n","    def forward(self, q, k, v, mask):\n","        query = self.w_q(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n","        key = self.w_k(k) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n","        value = self.w_v(v) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n","\n","        # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n","        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n","        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n","        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n","\n","        # Calculate attention\n","        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n","\n","        # Combine all the heads together\n","        # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n","        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n","\n","        # Multiply by Wo\n","        # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n","        return self.w_o(x)"]},{"cell_type":"markdown","source":["### Res block"],"metadata":{"id":"RsC17zpnxKJG"},"id":"RsC17zpnxKJG"},{"cell_type":"code","execution_count":null,"id":"6d7c400c","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.714984Z","iopub.status.busy":"2024-08-30T16:46:33.714669Z","iopub.status.idle":"2024-08-30T16:46:33.719924Z","shell.execute_reply":"2024-08-30T16:46:33.719132Z"},"papermill":{"duration":0.017619,"end_time":"2024-08-30T16:46:33.721915","exception":false,"start_time":"2024-08-30T16:46:33.704296","status":"completed"},"tags":[],"id":"6d7c400c"},"outputs":[],"source":["class ResidualConnection(nn.Module):\n","\n","        def __init__(self, features, dropout):\n","            super().__init__()\n","            self.dropout = nn.Dropout(dropout)\n","            self.norm = LayerNormalization(features)\n","\n","        def forward(self, x, sublayer):\n","            return x + self.dropout(sublayer(self.norm(x)))"]},{"cell_type":"markdown","source":["### Encoder block"],"metadata":{"id":"ILx2pSzyxMb-"},"id":"ILx2pSzyxMb-"},{"cell_type":"code","execution_count":null,"id":"675edd32","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.741849Z","iopub.status.busy":"2024-08-30T16:46:33.741341Z","iopub.status.idle":"2024-08-30T16:46:33.747657Z","shell.execute_reply":"2024-08-30T16:46:33.746786Z"},"papermill":{"duration":0.018309,"end_time":"2024-08-30T16:46:33.749580","exception":false,"start_time":"2024-08-30T16:46:33.731271","status":"completed"},"tags":[],"id":"675edd32"},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self,features, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock,dropout):\n","        super().__init__()\n","        self.self_attention_block = self_attention_block\n","        self.feed_forward_block = feed_forward_block\n","        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\n","\n","    def forward(self, x, src_mask):\n","        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n","        x = self.residual_connections[1](x, self.feed_forward_block)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"id":"1fdaad50","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.769241Z","iopub.status.busy":"2024-08-30T16:46:33.768975Z","iopub.status.idle":"2024-08-30T16:46:33.774330Z","shell.execute_reply":"2024-08-30T16:46:33.773535Z"},"papermill":{"duration":0.017336,"end_time":"2024-08-30T16:46:33.776371","exception":false,"start_time":"2024-08-30T16:46:33.759035","status":"completed"},"tags":[],"id":"1fdaad50"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self,features,layers: nn.ModuleList):\n","        super().__init__()\n","        self.layers = layers\n","        self.norm = LayerNormalization(features)\n","\n","    def forward(self, x, mask):\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","        return self.norm(x)\n"]},{"cell_type":"markdown","source":["### Decoder"],"metadata":{"id":"gqQV54TNxOfs"},"id":"gqQV54TNxOfs"},{"cell_type":"code","execution_count":null,"id":"eda2fd1f","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.795580Z","iopub.status.busy":"2024-08-30T16:46:33.795288Z","iopub.status.idle":"2024-08-30T16:46:33.802735Z","shell.execute_reply":"2024-08-30T16:46:33.801884Z"},"papermill":{"duration":0.019308,"end_time":"2024-08-30T16:46:33.804660","exception":false,"start_time":"2024-08-30T16:46:33.785352","status":"completed"},"tags":[],"id":"eda2fd1f"},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","\n","    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n","        super().__init__()\n","        self.self_attention_block = self_attention_block\n","        self.cross_attention_block = cross_attention_block\n","        self.feed_forward_block = feed_forward_block\n","        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])\n","\n","    def forward(self, x, encoder_output, src_mask, tgt_mask):\n","        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n","        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n","        x = self.residual_connections[2](x, self.feed_forward_block)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"id":"2ad32499","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.824235Z","iopub.status.busy":"2024-08-30T16:46:33.823970Z","iopub.status.idle":"2024-08-30T16:46:33.829315Z","shell.execute_reply":"2024-08-30T16:46:33.828539Z"},"papermill":{"duration":0.01762,"end_time":"2024-08-30T16:46:33.831463","exception":false,"start_time":"2024-08-30T16:46:33.813843","status":"completed"},"tags":[],"id":"2ad32499"},"outputs":[],"source":["class Decoder(nn.Module):\n","\n","    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n","        super().__init__()\n","        self.layers = layers\n","        self.norm = LayerNormalization(features)\n","\n","    def forward(self, x, encoder_output, src_mask, tgt_mask):\n","        for layer in self.layers:\n","            x = layer(x, encoder_output, src_mask, tgt_mask)\n","        return self.norm(x)\n"]},{"cell_type":"markdown","source":["### Linear Layer"],"metadata":{"id":"4iFitstExSWZ"},"id":"4iFitstExSWZ"},{"cell_type":"code","execution_count":null,"id":"5a8fb3b1","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.856318Z","iopub.status.busy":"2024-08-30T16:46:33.855917Z","iopub.status.idle":"2024-08-30T16:46:33.861571Z","shell.execute_reply":"2024-08-30T16:46:33.860390Z"},"papermill":{"duration":0.020949,"end_time":"2024-08-30T16:46:33.863969","exception":false,"start_time":"2024-08-30T16:46:33.843020","status":"completed"},"tags":[],"id":"5a8fb3b1"},"outputs":[],"source":["class ProjectionLayer(nn.Module):\n","\n","    def __init__(self, d_model, vocab_size):\n","        super().__init__()\n","        self.proj = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, x):\n","        return self.proj(x)"]},{"cell_type":"markdown","source":["### Combine all"],"metadata":{"id":"EjdgN6swxWxP"},"id":"EjdgN6swxWxP"},{"cell_type":"code","execution_count":null,"id":"5ae2c039","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.886936Z","iopub.status.busy":"2024-08-30T16:46:33.886656Z","iopub.status.idle":"2024-08-30T16:46:33.901344Z","shell.execute_reply":"2024-08-30T16:46:33.900436Z"},"papermill":{"duration":0.029563,"end_time":"2024-08-30T16:46:33.903178","exception":false,"start_time":"2024-08-30T16:46:33.873615","status":"completed"},"tags":[],"id":"5ae2c039"},"outputs":[],"source":["class Transformer(nn.Module):\n","\n","    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_embed = src_embed\n","        self.tgt_embed = tgt_embed\n","        self.src_pos = src_pos\n","        self.tgt_pos = tgt_pos\n","        self.projection_layer = projection_layer\n","\n","    def encode(self, src, src_mask):\n","        # (batch, seq_len, d_model)\n","        src = self.src_embed(src)\n","        src = self.src_pos(src)\n","        return self.encoder(src, src_mask)\n","\n","    def decode(self, encoder_output: torch.Tensor, src_mask: torch.Tensor, tgt: torch.Tensor, tgt_mask: torch.Tensor):\n","        # (batch, seq_len, d_model)\n","        tgt = self.tgt_embed(tgt)\n","        tgt = self.tgt_pos(tgt)\n","        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n","\n","    def project(self, x):\n","        # (batch, seq_len, vocab_size)\n","        return self.projection_layer(x)\n","\n","### Original Implemenetation with all the hyperparameters from the paper\n","\n","\n","# def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int=512, N: int=6, h: int=8, dropout: float=0.1, d_ff: int=2048) -> Transformer:\n","#     # Create the embedding layers\n","#     src_embed = InputEmbeddings(d_model, src_vocab_size)\n","#     tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n","\n","#     # Create the positional encoding layers\n","#     src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n","#     tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n","\n","#     # Create the encoder blocks\n","#     encoder_blocks = []\n","#     for _ in range(N):\n","#         encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n","#         feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n","#         encoder_block = EncoderBlock(d_model, encoder_self_attention_block, feed_forward_block, dropout)\n","#         encoder_blocks.append(encoder_block)\n","\n","#     # Create the decoder blocks\n","#     decoder_blocks = []\n","#     for _ in range(N):\n","#         decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n","#         decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n","#         feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n","#         decoder_block = DecoderBlock(d_model, decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n","#         decoder_blocks.append(decoder_block)\n","\n","#     # Create the encoder and decoder\n","#     encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n","#     decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n","\n","#     # Create the projection layer\n","#     projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n","\n","#     # Create the transformer\n","#     transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n","\n","#     # Initialize the parameters\n","#     for p in transformer.parameters():\n","#         if p.dim() > 1:\n","#             nn.init.xavier_uniform_(p)\n","\n","#     return transformer"]},{"cell_type":"code","execution_count":null,"id":"a4048b73","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.923211Z","iopub.status.busy":"2024-08-30T16:46:33.922964Z","iopub.status.idle":"2024-08-30T16:46:33.932370Z","shell.execute_reply":"2024-08-30T16:46:33.931569Z"},"papermill":{"duration":0.021612,"end_time":"2024-08-30T16:46:33.934244","exception":false,"start_time":"2024-08-30T16:46:33.912632","status":"completed"},"tags":[],"id":"a4048b73"},"outputs":[],"source":["### Hyperparameters changed so that training is lighter and faster\n","\n","def build_transformer(src_vocab_size, tgt_vocab_size, src_seq_len, tgt_seq_len, d_model=512, N=3, h=4, dropout=0.1, d_ff=1024) :\n","    # Create the embedding layers\n","    src_embed = InputEmbeddings(d_model, src_vocab_size)\n","    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n","\n","    # Create the positional encoding layers\n","    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n","    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n","\n","    # Create the encoder blocks\n","    encoder_blocks = []\n","    for _ in range(N):\n","        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n","        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n","        encoder_block = EncoderBlock(d_model, encoder_self_attention_block, feed_forward_block, dropout)\n","        encoder_blocks.append(encoder_block)\n","\n","    # Create the decoder blocks\n","    decoder_blocks = []\n","    for _ in range(N):\n","        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n","        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n","        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n","        decoder_block = DecoderBlock(d_model, decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n","        decoder_blocks.append(decoder_block)\n","\n","    # Create the encoder and decoder\n","    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n","    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n","\n","    # Create the projection layer\n","    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n","\n","    # Create the transformer\n","    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n","\n","    # Initialize the parameters\n","    for p in transformer.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","\n","    return transformer"]},{"cell_type":"markdown","source":["### Config"],"metadata":{"id":"CeSdn14ckayR"},"id":"CeSdn14ckayR"},{"cell_type":"code","execution_count":null,"id":"4b34af9a","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.954234Z","iopub.status.busy":"2024-08-30T16:46:33.953990Z","iopub.status.idle":"2024-08-30T16:46:33.961729Z","shell.execute_reply":"2024-08-30T16:46:33.960847Z"},"papermill":{"duration":0.019705,"end_time":"2024-08-30T16:46:33.963523","exception":false,"start_time":"2024-08-30T16:46:33.943818","status":"completed"},"tags":[],"id":"4b34af9a"},"outputs":[],"source":["from pathlib import Path\n","\n","def get_config():\n","    return {\n","        \"batch_size\": 8,\n","        \"num_epochs\": 15,\n","        \"lr\": 10**-4,\n","        \"seq_len\": 350,\n","        \"d_model\": 512,\n","        \"datasource\": 'opus_books',\n","        \"lang_src\": \"en\",\n","        \"lang_tgt\": \"mr\",\n","        \"model_folder\": \"weights\",\n","        \"model_basename\": \"tmodel_\",\n","        \"preload\": \"latest\",\n","        \"tokenizer_file\": \"tokenizer_{0}.json\",\n","        \"experiment_name\": \"runs/tmodel\"\n","    }\n","\n","def get_weights_file_path(config, epoch: str):\n","    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n","    model_filename = f\"{config['model_basename']}{epoch}.pt\"\n","    return str(Path('.') / model_folder / model_filename)\n","\n","# Find the latest weights file in the weights folder\n","def latest_weights_file_path(config):\n","    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n","    model_filename = f\"{config['model_basename']}*\"\n","    weights_files = list(Path(model_folder).glob(model_filename))\n","    if len(weights_files) == 0:\n","        return None\n","    weights_files.sort()\n","    return str(weights_files[-1])"]},{"cell_type":"markdown","source":["### Building Dataset"],"metadata":{"id":"V7W1zr03-FQG"},"id":"V7W1zr03-FQG"},{"cell_type":"code","execution_count":null,"id":"01bd031d","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:33.991028Z","iopub.status.busy":"2024-08-30T16:46:33.990609Z","iopub.status.idle":"2024-08-30T16:46:34.016366Z","shell.execute_reply":"2024-08-30T16:46:34.015224Z"},"papermill":{"duration":0.03978,"end_time":"2024-08-30T16:46:34.018266","exception":false,"start_time":"2024-08-30T16:46:33.978486","status":"completed"},"tags":[],"id":"01bd031d"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","\n","class BilingualDataset(Dataset):\n","\n","    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n","        super().__init__()\n","        self.seq_len = seq_len\n","\n","        self.ds = ds\n","        self.tokenizer_src = tokenizer_src\n","        self.tokenizer_tgt = tokenizer_tgt\n","        self.src_lang = src_lang\n","        self.tgt_lang = tgt_lang\n","\n","        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n","        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n","        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n","\n","    def __len__(self):\n","        return len(self.ds)\n","\n","    def __getitem__(self, idx):\n","        src_target_pair = self.ds[idx]\n","        src_text = src_target_pair['translation'][self.src_lang]\n","        tgt_text = src_target_pair['translation'][self.tgt_lang]\n","\n","        # Transform the text into tokens\n","        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n","        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n","\n","        # Add sos, eos and padding to each sentence\n","        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2  # We will add <s> and </s>\n","        # We will only add <s>, and </s> only on the label\n","        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1\n","\n","        # Make sure the number of padding tokens is not negative. If it is, the sentence is too long\n","        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n","            raise ValueError(\"Sentence is too long\")\n","\n","        # Add <s> and </s> token\n","        encoder_input = torch.cat(\n","            [\n","                self.sos_token,\n","                torch.tensor(enc_input_tokens, dtype=torch.int64),\n","                self.eos_token,\n","                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64),\n","            ],\n","            dim=0,\n","        )\n","\n","        # Add only <s> token\n","        decoder_input = torch.cat(\n","            [\n","                self.sos_token,\n","                torch.tensor(dec_input_tokens, dtype=torch.int64),\n","                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n","            ],\n","            dim=0,\n","        )\n","\n","        # Add only </s> token\n","        label = torch.cat(\n","            [\n","                torch.tensor(dec_input_tokens, dtype=torch.int64),\n","                self.eos_token,\n","                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n","            ],\n","            dim=0,\n","        )\n","\n","        # Double check the size of the tensors to make sure they are all seq_len long\n","        assert encoder_input.size(0) == self.seq_len\n","        assert decoder_input.size(0) == self.seq_len\n","        assert label.size(0) == self.seq_len\n","\n","        return {\n","            \"encoder_input\": encoder_input,  # (seq_len)\n","            \"decoder_input\": decoder_input,  # (seq_len)\n","            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(), # (1, 1, seq_len)\n","            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).int() & causal_mask(decoder_input.size(0)), # (1, seq_len) & (1, seq_len, seq_len),\n","            \"label\": label,  # (seq_len)\n","            \"src_text\": src_text,\n","            \"tgt_text\": tgt_text,\n","        }\n","\n","def causal_mask(size):\n","    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n","    return mask == 0"]},{"cell_type":"markdown","source":["### Inference"],"metadata":{"id":"VbJY8AXBx7Ul"},"id":"VbJY8AXBx7Ul"},{"cell_type":"code","execution_count":null,"id":"bd7790ed","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:34.046422Z","iopub.status.busy":"2024-08-30T16:46:34.045756Z","iopub.status.idle":"2024-08-30T16:46:50.144263Z","shell.execute_reply":"2024-08-30T16:46:50.143471Z"},"papermill":{"duration":16.116663,"end_time":"2024-08-30T16:46:50.146577","exception":false,"start_time":"2024-08-30T16:46:34.029914","status":"completed"},"tags":[],"id":"bd7790ed","outputId":"b479608a-55ca-4db1-a622-e03a02beea18"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/maverick/miniconda3/envs/transform/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torchtext.datasets as datasets\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torch.optim.lr_scheduler import LambdaLR\n","\n","import warnings\n","from tqdm import tqdm\n","import os\n","from pathlib import Path\n","\n","# Huggingface datasets and tokenizers\n","from datasets import load_dataset\n","from tokenizers import Tokenizer\n","from tokenizers.models import WordLevel\n","from tokenizers.trainers import WordLevelTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","\n","import torchmetrics\n","from torch.utils.tensorboard import SummaryWriter\n","\n","def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n","    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n","    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n","\n","    # Precompute the encoder output and reuse it for every step\n","    encoder_output = model.encode(source, source_mask)\n","    # Initialize the decoder input with the sos token\n","    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n","    while True:\n","        if decoder_input.size(1) == max_len:\n","            break\n","\n","        # build mask for target\n","        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n","\n","        # calculate output\n","        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n","\n","        # get next token\n","        prob = model.project(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        decoder_input = torch.cat(\n","            [decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1\n","        )\n","\n","        if next_word == eos_idx:\n","            break\n","\n","    return decoder_input.squeeze(0)\n","\n","\n","def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_step, writer, num_examples=2):\n","    model.eval()\n","    count = 0\n","\n","    source_texts = []\n","    expected = []\n","    predicted = []\n","\n","    try:\n","        # get the console window width\n","        with os.popen('stty size', 'r') as console:\n","            _, console_width = console.read().split()\n","            console_width = int(console_width)\n","    except:\n","        # If we can't get the console width, use 80 as default\n","        console_width = 80\n","\n","    with torch.no_grad():\n","        for batch in validation_ds:\n","            count += 1\n","            encoder_input = batch[\"encoder_input\"].to(device) # (b, seq_len)\n","            encoder_mask = batch[\"encoder_mask\"].to(device) # (b, 1, 1, seq_len)\n","\n","            # check that the batch size is 1\n","            assert encoder_input.size(\n","                0) == 1, \"Batch size must be 1 for validation\"\n","\n","            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n","\n","            source_text = batch[\"src_text\"][0]\n","            target_text = batch[\"tgt_text\"][0]\n","            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n","\n","            source_texts.append(source_text)\n","            expected.append(target_text)\n","            predicted.append(model_out_text)\n","\n","            # Print the source, target and model output\n","            print_msg('-'*console_width)\n","            print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n","            print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n","            print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n","\n","            if count == num_examples:\n","                print_msg('-'*console_width)\n","                break\n","\n","    if writer:\n","        # Evaluate the character error rate\n","        # Compute the char error rate\n","        metric = torchmetrics.CharErrorRate()\n","        cer = metric(predicted, expected)\n","        writer.add_scalar('validation cer', cer, global_step)\n","        writer.flush()\n","\n","        # Compute the word error rate\n","        metric = torchmetrics.WordErrorRate()\n","        wer = metric(predicted, expected)\n","        writer.add_scalar('validation wer', wer, global_step)\n","        writer.flush()\n","\n","        # Compute the BLEU metric\n","        metric = torchmetrics.BLEUScore()\n","        bleu = metric(predicted, expected)\n","        writer.add_scalar('validation BLEU', bleu, global_step)\n","        writer.flush()"]},{"cell_type":"markdown","source":["### Tokenizer"],"metadata":{"id":"j97ibFrlkWNn"},"id":"j97ibFrlkWNn"},{"cell_type":"code","execution_count":null,"id":"ecdcf13f","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:50.167203Z","iopub.status.busy":"2024-08-30T16:46:50.166692Z","iopub.status.idle":"2024-08-30T16:46:50.180553Z","shell.execute_reply":"2024-08-30T16:46:50.179704Z"},"papermill":{"duration":0.026129,"end_time":"2024-08-30T16:46:50.182606","exception":false,"start_time":"2024-08-30T16:46:50.156477","status":"completed"},"tags":[],"id":"ecdcf13f"},"outputs":[],"source":["def get_all_sentences(ds, lang):\n","    for item in ds:\n","        yield item['translation'][lang]\n","\n","def get_or_build_tokenizer(config, ds, lang):\n","    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n","    if not Path.exists(tokenizer_path):\n","        # Most code taken from: https://huggingface.co/docs/tokenizers/quicktour\n","        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n","        tokenizer.pre_tokenizer = Whitespace()\n","        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n","        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n","        tokenizer.save(str(tokenizer_path))\n","    else:\n","        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n","    return tokenizer\n","\n","def get_ds(config):\n","    # It only has the train split, so we divide it overselves\n","#     ds_raw = load_dataset(f\"{config['datasource']}\", f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n","    ds_raw = load_dataset(\"opus100\", \"en-mr\", split='train')\n","    print(\"Dataset fetched.\")\n","    # Build tokenizers\n","    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n","    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config['lang_tgt'])\n","\n","    # Keep 90% for training, 10% for validation\n","    train_ds_size = int(0.9 * len(ds_raw))\n","    val_ds_size = len(ds_raw) - train_ds_size\n","    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n","\n","    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n","    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n","\n","    # Find the maximum length of each sentence in the source and target sentence\n","    max_len_src = 0\n","    max_len_tgt = 0\n","\n","    for item in ds_raw:\n","        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n","        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n","        max_len_src = max(max_len_src, len(src_ids))\n","        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n","\n","    print(f'Max length of source sentence: {max_len_src}')\n","    print(f'Max length of target sentence: {max_len_tgt}')\n","\n","\n","    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n","    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n","\n","    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt"]},{"cell_type":"markdown","source":["### Training loop"],"metadata":{"id":"DFaZxOOQ-u-6"},"id":"DFaZxOOQ-u-6"},{"cell_type":"code","execution_count":null,"id":"fadf68e0","metadata":{"execution":{"iopub.execute_input":"2024-08-30T16:46:50.202890Z","iopub.status.busy":"2024-08-30T16:46:50.202635Z","iopub.status.idle":"2024-08-31T01:17:11.285181Z","shell.execute_reply":"2024-08-31T01:17:11.283534Z"},"papermill":{"duration":30621.096264,"end_time":"2024-08-31T01:17:11.288249","exception":false,"start_time":"2024-08-30T16:46:50.191985","status":"completed"},"tags":[],"id":"fadf68e0","outputId":"d51b3295-a13c-4c78-ceea-34d593befd17"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","Device name: NVIDIA GeForce RTX 4050 Laptop GPU\n","Device memory: 5.99658203125 GB\n","Dataset fetched.\n","Max length of source sentence: 289\n","Max length of target sentence: 261\n","No model to preload, starting from scratch\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 00: 100%|██████████| 3039/3039 [05:46<00:00,  8.77it/s, loss=4.429]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Abort.\n","    TARGET: वििच्छेद करा\n"," PREDICTED: ते .\n","--------------------------------------------------------------------------------\n","    SOURCE: If he should be busy, help him.\n","    TARGET: जर तो व्यग्र असला तर त्याची मदत करा.\n"," PREDICTED: तो , तो .\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 01: 100%|██████████| 3039/3039 [05:45<00:00,  8.80it/s, loss=5.769]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Konqueror\n","    TARGET: कॉन्करर\n"," PREDICTED: @ info\n","--------------------------------------------------------------------------------\n","    SOURCE: Crash report\n","    TARGET: क्रॅश अहवाल\n"," PREDICTED: @ info\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 02: 100%|██████████| 3039/3039 [05:45<00:00,  8.79it/s, loss=3.953]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: In India, the cow is a sacred animal.\n","    TARGET: भारतात गाय ही एक पवित्र पशु आहे.\n"," PREDICTED: , .\n","--------------------------------------------------------------------------------\n","    SOURCE: X DVI\n","    TARGET: X DVIGenericName\n"," PREDICTED: एक्स\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 03: 100%|██████████| 3039/3039 [05:45<00:00,  8.80it/s, loss=3.588]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Forget Tom.\n","    TARGET: टॉमला विसरून जा.\n"," PREDICTED: टॉमला बघ .\n","--------------------------------------------------------------------------------\n","    SOURCE: Patrick Dowler\n","    TARGET: Patrick Dowler\n"," PREDICTED: \n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 04: 100%|██████████| 3039/3039 [05:45<00:00,  8.80it/s, loss=2.982]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Why don't you take a taxi?\n","    TARGET: तुम्ही टॅक्सी का नाही करत?\n"," PREDICTED: तू टॅक्सी का नाही ?\n","--------------------------------------------------------------------------------\n","    SOURCE: Everybody's getting rich but me.\n","    TARGET: मला सोडल्यास सर्वच श्रीमंत होत आहेत.\n"," PREDICTED: तो श्रीमंत .\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 05: 100%|██████████| 3039/3039 [05:45<00:00,  8.80it/s, loss=1.975]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Button Text\n","    TARGET: बटण पाठ्य\n"," PREDICTED: पाठ्य पाठ्य\n","--------------------------------------------------------------------------------\n","    SOURCE: No service matching the requirements was found.\n","    TARGET: आवश्यकतानुरूप सेवा जुळवणी नंतर आढळले नाही.\n"," PREDICTED: सेवा % 1 आढळले नाही .\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 06: 100%|██████████| 3039/3039 [05:45<00:00,  8.80it/s, loss=2.115]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Geert Jansen\n","    TARGET: गीर्त जानसन\n"," PREDICTED: गीर्त जानसन\n","--------------------------------------------------------------------------------\n","    SOURCE: I am 19 years old.\n","    TARGET: मी १९ वर्षांचा आहे.\n"," PREDICTED: मी वर्ष आहे .\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 07: 100%|██████████| 3039/3039 [05:45<00:00,  8.80it/s, loss=2.134]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Which is more important, me or your job?\n","    TARGET: जास्त महत्त्वाचं काय आहे, मी की तुझी नोकरी?\n"," PREDICTED: तुझं आहे , आता की तुझं ?\n","--------------------------------------------------------------------------------\n","    SOURCE: We don't have any sugar.\n","    TARGET: आपल्याकडे साखर अजिबात नाहीये.\n"," PREDICTED: आपल्याकडे साखर नाही आहे .\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 08: 100%|██████████| 3039/3039 [05:45<00:00,  8.80it/s, loss=2.058]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Signaled target abort\n","    TARGET: लक्ष्य नष्ट करण्याकरीता संकेत पाठविले\n"," PREDICTED: लक्ष्य नष्ट करण्याकरीता संकेत पाठविले\n","--------------------------------------------------------------------------------\n","    SOURCE: Multi-Channel\n","    TARGET: बहु- मार्ग\n"," PREDICTED: -\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 09: 100%|██████████| 3039/3039 [05:45<00:00,  8.79it/s, loss=1.683]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Build Index\n","    TARGET: इन्डेक्स बिल्ड करा\n"," PREDICTED: इनडेक्स बिल्ड करा\n","--------------------------------------------------------------------------------\n","    SOURCE: We are his sons.\n","    TARGET: आम्ही त्याची मुलं आहोत.\n"," PREDICTED: आपण त्याची मुलं आहोत .\n","--------------------------------------------------------------------------------\n","Model saved at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 10: 100%|██████████| 3039/3039 [05:45<00:00,  8.79it/s, loss=1.748]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Where do you watch television?\n","    TARGET: तू टीव्ही कुठे बघतोस?\n"," PREDICTED: तू टीव्ही कुठे ?\n","--------------------------------------------------------------------------------\n","    SOURCE: She looks like her aunt.\n","    TARGET: ती तिच्या मावशीसारखी दिसते.\n"," PREDICTED: ती तिच्या दिसते .\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 11: 100%|██████████| 3039/3039 [05:45<00:00,  8.79it/s, loss=2.315]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: URI\n","    TARGET: URI\n"," PREDICTED: URI URI @ item :: intable\n","--------------------------------------------------------------------------------\n","    SOURCE: I am downloading books.\n","    TARGET: मी पुस्तकं डाउनलोड करतेय.\n"," PREDICTED: मी पुस्तकं डाउनलोड करतोय .\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 12: 100%|██████████| 3039/3039 [05:45<00:00,  8.79it/s, loss=2.602]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Button\n","    TARGET: बटण\n"," PREDICTED: बटण\n","--------------------------------------------------------------------------------\n","    SOURCE: Product: %1 (%2)\n","    TARGET: @ info bug report label and value\n"," PREDICTED: :% 1 (% 2 )\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 13: 100%|██████████| 3039/3039 [05:45<00:00,  8.80it/s, loss=2.024]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: Show progress information (even if'silent 'mode is on)\n","    TARGET: प्रगतीविषयक माहिती दर्शवा (जरी ते 'शांत' पध्दतीत कार्यक्षम आहे)\n"," PREDICTED: प्रगती माहिती दर्शवा ( , दाखलन पासून प्रगती दर्शवा )\n","--------------------------------------------------------------------------------\n","    SOURCE: Ricky, this is my friend Suzuki.\n","    TARGET: रिकी, ही आहे माझी मैत्रिण, सुजुकी.\n"," PREDICTED: रिकी , हा आहे माझा मित्र , सुजुकी .\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Processing Epoch 14: 100%|██████████| 3039/3039 [05:45<00:00,  8.79it/s, loss=1.725]\n","stty: 'standard input': Inappropriate ioctl for device\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","    SOURCE: That's Tom's girl.\n","    TARGET: ती टॉमची मुलगी आहे.\n"," PREDICTED: ती टॉमची मुलगी आहे .\n","--------------------------------------------------------------------------------\n","    SOURCE: UADescription (IE 6.0 on Win XP)\n","    TARGET: UAडिस्क्रिप्शन (IE 6. 0 Win XP वर) Name\n"," PREDICTED: UAडिस्क्रिप्शन ( IE 6 . 0 Win XP वर ) Name\n","--------------------------------------------------------------------------------\n"]}],"source":["def get_model(config, vocab_src_len, vocab_tgt_len):\n","    model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config['seq_len'], d_model=config['d_model'])\n","    return model\n","\n","def train_model(config):\n","    # Define the device\n","    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n","    print(\"Using device:\", device)\n","    if (device == 'cuda'):\n","        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n","        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n","    elif (device == 'mps'):\n","        print(f\"Device name: <mps>\")\n","    else:\n","        print(\"NOTE: If you have a GPU, consider using it for training.\")\n","        print(\"      On a Windows machine with NVidia GPU, check this video: https://www.youtube.com/watch?v=GMSjDTU8Zlc\")\n","        print(\"      On a Mac machine, run: pip3 install --pre torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/nightly/cpu\")\n","    device = torch.device(device)\n","\n","    # Make sure the weights folder exists\n","    Path(f\"{config['datasource']}_{config['model_folder']}\").mkdir(parents=True, exist_ok=True)\n","\n","    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n","    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n","    # Tensorboard\n","    writer = SummaryWriter(config['experiment_name'])\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n","\n","    # If the user specified a model to preload before training, load it\n","    initial_epoch = 0\n","    global_step = 0\n","    preload = config['preload']\n","    model_filename = latest_weights_file_path(config) if preload == 'latest' else get_weights_file_path(config, preload) if preload else None\n","    if model_filename:\n","        print(f'Preloading model {model_filename}')\n","        state = torch.load(model_filename)\n","        model.load_state_dict(state['model_state_dict'])\n","        initial_epoch = state['epoch'] + 1\n","        optimizer.load_state_dict(state['optimizer_state_dict'])\n","        global_step = state['global_step']\n","    else:\n","        print('No model to preload, starting from scratch')\n","\n","    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n","\n","    for epoch in range(initial_epoch, config['num_epochs']):\n","        torch.cuda.empty_cache()\n","        model.train()\n","        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n","        for batch in batch_iterator:\n","\n","            encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n","            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n","            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n","            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n","\n","            # Run the tensors through the encoder, decoder and the projection layer\n","            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n","            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n","            proj_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n","\n","            # Compare the output with the label\n","            label = batch['label'].to(device) # (B, seq_len)\n","\n","            # Compute the loss using a simple cross entropy\n","            # (B,seq_len,tgt_vocab_size) ---> (B*seq_length, tgt_vocab_size)\n","            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n","            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n","\n","            # Log the loss\n","            writer.add_scalar('train loss', loss.item(), global_step)\n","            writer.flush()\n","\n","            # Backpropagate the loss\n","            loss.backward()\n","\n","            # Update the weights\n","            optimizer.step()\n","            optimizer.zero_grad(set_to_none=True)\n","\n","            global_step += 1\n","\n","        # Run validation at the end of every epoch\n","        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n","\n","        # Save the model at the end of every epoch\n","        if (epoch + 1) % 10 == 0:\n","                model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n","                torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'global_step': global_step\n","                }, model_filename)\n","                print(f\"Model saved at epoch {epoch + 1}\")\n","\n","\n","if __name__ == '__main__':\n","    warnings.filterwarnings(\"ignore\")\n","    config = get_config()\n","    train_model(config)"]},{"cell_type":"code","execution_count":null,"id":"1c62f55e","metadata":{"papermill":{"duration":6.241649,"end_time":"2024-08-31T01:17:23.890552","exception":false,"start_time":"2024-08-31T01:17:17.648903","status":"completed"},"tags":[],"id":"1c62f55e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0e7fc75c","metadata":{"papermill":{"duration":6.181923,"end_time":"2024-08-31T01:17:36.268058","exception":false,"start_time":"2024-08-31T01:17:30.086135","status":"completed"},"tags":[],"id":"0e7fc75c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"76172b02","metadata":{"papermill":{"duration":6.355548,"end_time":"2024-08-31T01:17:48.786447","exception":false,"start_time":"2024-08-31T01:17:42.430899","status":"completed"},"tags":[],"id":"76172b02"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"43572282","metadata":{"papermill":{"duration":6.12924,"end_time":"2024-08-31T01:18:01.165322","exception":false,"start_time":"2024-08-31T01:17:55.036082","status":"completed"},"tags":[],"id":"43572282"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"64292ac8","metadata":{"papermill":{"duration":6.137291,"end_time":"2024-08-31T01:18:13.492297","exception":false,"start_time":"2024-08-31T01:18:07.355006","status":"completed"},"tags":[],"id":"64292ac8"},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"transform","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"papermill":{"default_parameters":{},"duration":30716.357427,"end_time":"2024-08-31T01:18:23.074492","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-08-30T16:46:26.717065","version":"2.5.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}